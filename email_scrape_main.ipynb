{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samuel.taylor\\OneDrive - Green Dot Public Schools\\Desktop\\Git_Directory\\CP\\CustomPlanet_Work\\Email_Scraper\\Scraping_Emails\\modules\\db_operations_aws.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_SQL = pd.read_sql_query(query, con=self.conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prior Unique Subject Line: Official MLB Jerseys in Stock!!\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Official MLB Jerseys in Stock!! in the outbox with a filter date of 02/19/2024\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Delivery Status Notification in the inbox with a filter date of 02/19/2024\n",
      "No bad emails to update with Official MLB Jerseys in Stock!!\n",
      "No emails to update\n",
      "\n",
      "\n",
      "Prior Unique Subject Line: Official Nike MLB Jerseys In Stock!!\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Official Nike MLB Jerseys In Stock!! in the outbox with a filter date of 02/19/2024\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Delivery Status Notification in the inbox with a filter date of 02/19/2024\n",
      "No bad emails to update with Official Nike MLB Jerseys In Stock!!\n",
      "No emails to update\n",
      "\n",
      "\n",
      "Prior Unique Subject Line: Official MLB Little League Nike Jerseys - IN STOCK!!\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Official MLB Little League Nike Jerseys - IN STOCK!! in the outbox with a filter date of 02/19/2024\n",
      "Prior Unique Subject Line There are no responses to the specified emails search criteria Delivery Status Notification in the inbox with a filter date of 02/19/2024\n",
      "No bad emails to update with Official MLB Little League Nike Jerseys - IN STOCK!!\n",
      "No emails to update\n",
      "Current Subject Line There are no responses to the specified emails search criteria Official MLB Jerseys in the inbox with a filter date of 02/01/2024\n",
      "Current Subject Line There are no responses to the specified emails search criteria Official MLB Jerseys in the outbox with a filter date of 02/01/2024\n",
      "Outbox is an empty frame\n",
      "Thread is an empty frame\n"
     ]
    }
   ],
   "source": [
    "#2000 emails sent to email_history took 5 minutes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Mute pandas UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "\n",
    "#create log dir and file\n",
    "logpath_creation = os.getcwd() + '\\\\Logs'\n",
    "if not os.path.exists(logpath_creation):\n",
    "    os.makedirs(logpath_creation)\n",
    "\n",
    "logging.basicConfig(filename= logpath_creation + '\\\\Email_Scraper.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', force=True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from config import imap_password_customplanet, db_username, db_password\n",
    "from Scraping_Emails.modules.scrapes import scrape\n",
    "from Scraping_Emails.modules.db_operations_aws import DatabaseConnector\n",
    "from MySQL_Scripts.modules.email_failures import  gather_and_send_bad_emails_to_db\n",
    "\n",
    "#What is the difference between update_bad_emails & gather and send bad emails to db\n",
    "#Consolidating update_bad_emails to email_faulures\n",
    "\n",
    "\n",
    "email_address = 'team@customplanet.com'\n",
    "email_pass = imap_password_customplanet\n",
    "server = 'emailcampaign.c9vhoi6ncot7.us-east-1.rds.amazonaws.com'\n",
    "database = 'emailcampaign'\n",
    "db = 'emailcampaign'\n",
    "\n",
    "\n",
    "# ----------------------------------Updating Faulty Emails in the DB before Send----------------------------------\n",
    "#Searches GMAIL on the daily for bad emails that were sent back, and sends data to unsubscribed email table\n",
    "#Goes through all distinct subject lines in the DB\n",
    "\n",
    "db_connector_email_history = DatabaseConnector(server, database, db_username, db_password, db, 'email_history')\n",
    "query = db_connector_email_history.SQL_query('SELECT DISTINCT subject FROM [emailcampaign].[dbo].[email_history]')\n",
    "    \n",
    "#Iterate through all unique subject lines to update the db table with all faulty email addresses\n",
    "for line in query['subject']:\n",
    "    print('\\n')\n",
    "    print(f'Prior Unique Subject Line: {line}')\n",
    "    gather_and_send_bad_emails_to_db(line, email_address, email_pass, 'Prior Unique Subject Line')\n",
    "\n",
    "# ------------------------------------packaging process into final function----------------------------------------\n",
    "\n",
    "def process(subject_line, email_address, email_pass, start_date):\n",
    "\n",
    "    #create the msgs via scrape, then iterate through list of messages, and lastly cleanse frame\n",
    "    email_address = 'team@customplanet.com'\n",
    "    email_pass = imap_password_customplanet\n",
    " \n",
    "    msgs_inbox = scrape.scrape_msgs_outbox_or_inbox('inbox', subject_line, email_address, email_pass, start_date, 'Current Subject Line')\n",
    "    inbox = scrape.create_msg_frame(msgs_inbox)\n",
    "    inbox = scrape.cleanse_frame(inbox, 'inbox')\n",
    "    inbox.name = 'inbox'\n",
    "\n",
    "    msgs_outbox = scrape.scrape_msgs_outbox_or_inbox('outbox', subject_line, email_address, email_pass, start_date, 'Current Subject Line')\n",
    "    outbox = scrape.create_msg_frame(msgs_outbox)\n",
    "    outbox = scrape.cleanse_frame(outbox, 'outbox')\n",
    "    outbox.name = 'outbox'\n",
    "        \n",
    "    if inbox.empty == True:\n",
    "        thread = pd.DataFrame()\n",
    "        pass\n",
    "    else: #this is a left merge on outbox\n",
    "        thread = scrape.piece_together(outbox, inbox)\n",
    "        thread = scrape.assign_sentiment(thread)\n",
    "       \n",
    "    # #If message was accidentally triggered more than once\n",
    "    thread = thread.drop_duplicates(subset = ['subject', 'to'], keep='last')\n",
    "    thread.reset_index(drop = True, inplace = True)\n",
    "    outbox = scrape.map_reply_outbox(thread, outbox)\n",
    "\n",
    "    return(inbox, outbox, thread)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "#Get inbox, outbox, and create thread with given subject line back to given date\n",
    "subject_line = 'Official MLB Jerseys'\n",
    "inbox, outbox, thread= process(subject_line, email_address, email_pass, '02/01/2024')\n",
    "\n",
    "\n",
    "# Instantiate the DatabaseConnector class, send over all emails in outbox variable to email_history table that contain the subject line \n",
    "#Optional column identifiers to add in to the DB\n",
    "outbox['email_campaign_tag'] = 'Majestic Round 2'\n",
    "outbox['sport'] = 'Baseball'    #frame   #table_name\n",
    "\n",
    "# ----------Send outbox\n",
    "\n",
    "if outbox.empty != True:\n",
    "    db_connector_email_history.send(outbox, 'email_history')\n",
    "else:\n",
    "    logging.info('Outbox is an empty frame')\n",
    "    print('Outbox is an empty frame')\n",
    "\n",
    "# ----------Send thread\n",
    "\n",
    "if thread.empty != True:\n",
    "    db_connector_thread = DatabaseConnector(server, database, db_username, db_password, db, 'thread')\n",
    "    db_connector_thread.send(thread, 'thread')\n",
    "    pre_existing_thread_updates = db_connector_thread.update_reply_thread(thread)\n",
    "else:\n",
    "    logging.info('Thread is an empty frame')\n",
    "    print('Thread is an empty frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure out how to create a space when de-bugging\n",
    "# New logging instance\n",
    "# 20-Feb-24 16:24:16 - There are no responses to the specified emails search criteria Official MLB Little League Nike Jerseys - IN STOCK!! in the outbox with a filter date of 02/19/2024\n",
    "# 20-Feb-24 16:24:17 - There are no responses to the specified emails search criteria Delivery Status Notification in the inbox with a filter date of 02/19/2024\n",
    "# 20-Feb-24 16:24:17 - No bad emails to update\n",
    "# 20-Feb-24 16:24:19 - You have email responses to the specified search criteria Official MLB Jerseys in the inbox with a filter date of 2/01/2023\n",
    "# 20-Feb-24 16:24:23 - You have email responses to the specified search criteria Official MLB Jerseys in the outbox with a filter date of 2/01/2023\n",
    "\n",
    "\n",
    "\n",
    "#Within the debug figure out how to log out better. \n",
    "#Be able to decipher what is a prior line, versus what is current\n",
    "\n",
    "# scrape_msgs_outbox_or_inbox #called within this func\n",
    "#also nested in the one below\n",
    "# gather_and_send_bad_emails_to_db, still hits the scrape_msgs_outbox_or_inbox func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL\n",
    "#All main scripts be moved to the root level, reference a singular config file. \n",
    "\n",
    "#Clean up codebase with relative imports. \n",
    "#Make Sending and Scraping reference the same code base\n",
    "\n",
    "#Create PNGs on hoodies images using Selenium. \n",
    "\n",
    "#Write directly to MySQL DB\n",
    "\n",
    "#Refine NLP\n",
    "\n",
    "#Thirdly, what if the email is not directly replied to. In that case. \n",
    "# The scenario would be the following, email campaign sent out to sammytaylor2006@yahoo.com\n",
    "#The customer indirectly reaches out to CP, and not through the thread. This calls for a seperate table.\n",
    "# and a seperate scrape \n",
    "\n",
    "#Integrate SSIS at some point for views\n",
    "#Integrating prior orders and linking them in a SQL view.\n",
    "\n",
    "#Predictive analytics based on prior orders\n",
    "\n",
    "#Put the PNG on the given sport jersey\n",
    "#Clean the CSV to iterate properly, this should be done. \n",
    "#Singularize the db_operations to reference in both"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
